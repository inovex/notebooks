{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantization_aware_training_mobilenetv2_cars196.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR33D7bApGa4"
      },
      "source": [
        "![inovex logo mini240px.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os1l9VGp3Hfq"
      },
      "source": [
        "# Quantization aware training (QAT) of a MobileNet classifier\n",
        "\n",
        "\n",
        "This notebook illustrates how you can use quantization aware trainig on a pre-trained MobileNetV2 model to create your own, lightweight neural network. \n",
        "This notebook is companion material to the blog post series *Deep Learning for mobile devices with TensorFlow Lite*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRBC0PZfoopj"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umj6ZnVhgCp1"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "The following cell fetches the whole Dataset from TFDS and store it in the runtime. Note that the data will be lost if you lose your runtime. If you want to avoid this, consider connecting your Google drive with the runtime and store your dataset in a drive folder. \n",
        "\n",
        "\n",
        "We use the TFDS slicing API to reserve 80% of the original train split as actual training data and 20% as validation data to verify the training progress after each epoch. We want to see which features are provided by the generator, so we add the `with_info=True` argument to the function call.\n",
        "\n",
        "This is going to run for a few minutes, so you can probably get you some coffee ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtqll8i_ovQZ"
      },
      "source": [
        "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
        "    'cars196',\n",
        "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "    with_info=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzXME7xM_IQ6"
      },
      "source": [
        "## What have we got from our Dataset?\n",
        "\n",
        "Let's examine the content of the Dataset description that we downloaded alongside our copy of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkRbIVgacfHV"
      },
      "source": [
        "metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoUyOteeBFG3"
      },
      "source": [
        "Alright, so we have a total of 16185 images split roughly into a 50-50 train/test split. Each sample consists of a `BBoxFeature`, which contains normalized bounding box coordinates in the order [ymin, xmin, ymax, xmax], a numeric label and the image of the car. Lets plot some of the cars together with their bounding boxes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKaI-lPT_Pcr"
      },
      "source": [
        "# Visualize samples and features\n",
        "\n",
        "Unfortunately, the dataset provider only provides numerical labels. However, for visualization and especially when deploying our model, we want to display the exact make, model and year of the car instead of a cryptic number that nobody understands. I copied the following list with label names from the source code of the dataset provider. You can find the source code [on GitHub](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/cars196.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmHt-549_sxq"
      },
      "source": [
        "CLASS_NAMES = [\n",
        "    'AM General Hummer SUV 2000', 'Acura RL Sedan 2012', 'Acura TL Sedan 2012',\n",
        "    'Acura TL Type-S 2008', 'Acura TSX Sedan 2012', 'Acura Integra Type R 2001',\n",
        "    'Acura ZDX Hatchback 2012', 'Aston Martin V8 Vantage Convertible 2012',\n",
        "    'Aston Martin V8 Vantage Coupe 2012',\n",
        "    'Aston Martin Virage Convertible 2012', 'Aston Martin Virage Coupe 2012',\n",
        "    'Audi RS 4 Convertible 2008', 'Audi A5 Coupe 2012', 'Audi TTS Coupe 2012',\n",
        "    'Audi R8 Coupe 2012', 'Audi V8 Sedan 1994', 'Audi 100 Sedan 1994',\n",
        "    'Audi 100 Wagon 1994', 'Audi TT Hatchback 2011', 'Audi S6 Sedan 2011',\n",
        "    'Audi S5 Convertible 2012', 'Audi S5 Coupe 2012', 'Audi S4 Sedan 2012',\n",
        "    'Audi S4 Sedan 2007', 'Audi TT RS Coupe 2012',\n",
        "    'BMW ActiveHybrid 5 Sedan 2012', 'BMW 1 Series Convertible 2012',\n",
        "    'BMW 1 Series Coupe 2012', 'BMW 3 Series Sedan 2012',\n",
        "    'BMW 3 Series Wagon 2012', 'BMW 6 Series Convertible 2007',\n",
        "    'BMW X5 SUV 2007', 'BMW X6 SUV 2012', 'BMW M3 Coupe 2012',\n",
        "    'BMW M5 Sedan 2010', 'BMW M6 Convertible 2010', 'BMW X3 SUV 2012',\n",
        "    'BMW Z4 Convertible 2012',\n",
        "    'Bentley Continental Supersports Conv. Convertible 2012',\n",
        "    'Bentley Arnage Sedan 2009', 'Bentley Mulsanne Sedan 2011',\n",
        "    'Bentley Continental GT Coupe 2012', 'Bentley Continental GT Coupe 2007',\n",
        "    'Bentley Continental Flying Spur Sedan 2007',\n",
        "    'Bugatti Veyron 16.4 Convertible 2009', 'Bugatti Veyron 16.4 Coupe 2009',\n",
        "    'Buick Regal GS 2012', 'Buick Rainier SUV 2007', 'Buick Verano Sedan 2012',\n",
        "    'Buick Enclave SUV 2012', 'Cadillac CTS-V Sedan 2012',\n",
        "    'Cadillac SRX SUV 2012', 'Cadillac Escalade EXT Crew Cab 2007',\n",
        "    'Chevrolet Silverado 1500 Hybrid Crew Cab 2012',\n",
        "    'Chevrolet Corvette Convertible 2012', 'Chevrolet Corvette ZR1 2012',\n",
        "    'Chevrolet Corvette Ron Fellows Edition Z06 2007',\n",
        "    'Chevrolet Traverse SUV 2012', 'Chevrolet Camaro Convertible 2012',\n",
        "    'Chevrolet HHR SS 2010', 'Chevrolet Impala Sedan 2007',\n",
        "    'Chevrolet Tahoe Hybrid SUV 2012', 'Chevrolet Sonic Sedan 2012',\n",
        "    'Chevrolet Express Cargo Van 2007', 'Chevrolet Avalanche Crew Cab 2012',\n",
        "    'Chevrolet Cobalt SS 2010', 'Chevrolet Malibu Hybrid Sedan 2010',\n",
        "    'Chevrolet TrailBlazer SS 2009',\n",
        "    'Chevrolet Silverado 2500HD Regular Cab 2012',\n",
        "    'Chevrolet Silverado 1500 Classic Extended Cab 2007',\n",
        "    'Chevrolet Express Van 2007', 'Chevrolet Monte Carlo Coupe 2007',\n",
        "    'Chevrolet Malibu Sedan 2007', 'Chevrolet Silverado 1500 Extended Cab 2012',\n",
        "    'Chevrolet Silverado 1500 Regular Cab 2012', 'Chrysler Aspen SUV 2009',\n",
        "    'Chrysler Sebring Convertible 2010',\n",
        "    'Chrysler Town and Country Minivan 2012', 'Chrysler 300 SRT-8 2010',\n",
        "    'Chrysler Crossfire Convertible 2008',\n",
        "    'Chrysler PT Cruiser Convertible 2008', 'Daewoo Nubira Wagon 2002',\n",
        "    'Dodge Caliber Wagon 2012', 'Dodge Caliber Wagon 2007',\n",
        "    'Dodge Caravan Minivan 1997', 'Dodge Ram Pickup 3500 Crew Cab 2010',\n",
        "    'Dodge Ram Pickup 3500 Quad Cab 2009', 'Dodge Sprinter Cargo Van 2009',\n",
        "    'Dodge Journey SUV 2012', 'Dodge Dakota Crew Cab 2010',\n",
        "    'Dodge Dakota Club Cab 2007', 'Dodge Magnum Wagon 2008',\n",
        "    'Dodge Challenger SRT8 2011', 'Dodge Durango SUV 2012',\n",
        "    'Dodge Durango SUV 2007', 'Dodge Charger Sedan 2012',\n",
        "    'Dodge Charger SRT-8 2009', 'Eagle Talon Hatchback 1998',\n",
        "    'FIAT 500 Abarth 2012', 'FIAT 500 Convertible 2012',\n",
        "    'Ferrari FF Coupe 2012', 'Ferrari California Convertible 2012',\n",
        "    'Ferrari 458 Italia Convertible 2012', 'Ferrari 458 Italia Coupe 2012',\n",
        "    'Fisker Karma Sedan 2012', 'Ford F-450 Super Duty Crew Cab 2012',\n",
        "    'Ford Mustang Convertible 2007', 'Ford Freestar Minivan 2007',\n",
        "    'Ford Expedition EL SUV 2009', 'Ford Edge SUV 2012',\n",
        "    'Ford Ranger SuperCab 2011', 'Ford GT Coupe 2006',\n",
        "    'Ford F-150 Regular Cab 2012', 'Ford F-150 Regular Cab 2007',\n",
        "    'Ford Focus Sedan 2007', 'Ford E-Series Wagon Van 2012',\n",
        "    'Ford Fiesta Sedan 2012', 'GMC Terrain SUV 2012', 'GMC Savana Van 2012',\n",
        "    'GMC Yukon Hybrid SUV 2012', 'GMC Acadia SUV 2012',\n",
        "    'GMC Canyon Extended Cab 2012', 'Geo Metro Convertible 1993',\n",
        "    'HUMMER H3T Crew Cab 2010', 'HUMMER H2 SUT Crew Cab 2009',\n",
        "    'Honda Odyssey Minivan 2012', 'Honda Odyssey Minivan 2007',\n",
        "    'Honda Accord Coupe 2012', 'Honda Accord Sedan 2012',\n",
        "    'Hyundai Veloster Hatchback 2012', 'Hyundai Santa Fe SUV 2012',\n",
        "    'Hyundai Tucson SUV 2012', 'Hyundai Veracruz SUV 2012',\n",
        "    'Hyundai Sonata Hybrid Sedan 2012', 'Hyundai Elantra Sedan 2007',\n",
        "    'Hyundai Accent Sedan 2012', 'Hyundai Genesis Sedan 2012',\n",
        "    'Hyundai Sonata Sedan 2012', 'Hyundai Elantra Touring Hatchback 2012',\n",
        "    'Hyundai Azera Sedan 2012', 'Infiniti G Coupe IPL 2012',\n",
        "    'Infiniti QX56 SUV 2011', 'Isuzu Ascender SUV 2008', 'Jaguar XK XKR 2012',\n",
        "    'Jeep Patriot SUV 2012', 'Jeep Wrangler SUV 2012', 'Jeep Liberty SUV 2012',\n",
        "    'Jeep Grand Cherokee SUV 2012', 'Jeep Compass SUV 2012',\n",
        "    'Lamborghini Reventon Coupe 2008', 'Lamborghini Aventador Coupe 2012',\n",
        "    'Lamborghini Gallardo LP 570-4 Superleggera 2012',\n",
        "    'Lamborghini Diablo Coupe 2001', 'Land Rover Range Rover SUV 2012',\n",
        "    'Land Rover LR2 SUV 2012', 'Lincoln Town Car Sedan 2011',\n",
        "    'MINI Cooper Roadster Convertible 2012',\n",
        "    'Maybach Landaulet Convertible 2012', 'Mazda Tribute SUV 2011',\n",
        "    'McLaren MP4-12C Coupe 2012', 'Mercedes-Benz 300-Class Convertible 1993',\n",
        "    'Mercedes-Benz C-Class Sedan 2012', 'Mercedes-Benz SL-Class Coupe 2009',\n",
        "    'Mercedes-Benz E-Class Sedan 2012', 'Mercedes-Benz S-Class Sedan 2012',\n",
        "    'Mercedes-Benz Sprinter Van 2012', 'Mitsubishi Lancer Sedan 2012',\n",
        "    'Nissan Leaf Hatchback 2012', 'Nissan NV Passenger Van 2012',\n",
        "    'Nissan Juke Hatchback 2012', 'Nissan 240SX Coupe 1998',\n",
        "    'Plymouth Neon Coupe 1999', 'Porsche Panamera Sedan 2012',\n",
        "    'Ram C/V Cargo Van Minivan 2012',\n",
        "    'Rolls-Royce Phantom Drophead Coupe Convertible 2012',\n",
        "    'Rolls-Royce Ghost Sedan 2012', 'Rolls-Royce Phantom Sedan 2012',\n",
        "    'Scion xD Hatchback 2012', 'Spyker C8 Convertible 2009',\n",
        "    'Spyker C8 Coupe 2009', 'Suzuki Aerio Sedan 2007',\n",
        "    'Suzuki Kizashi Sedan 2012', 'Suzuki SX4 Hatchback 2012',\n",
        "    'Suzuki SX4 Sedan 2012', 'Tesla Model S Sedan 2012',\n",
        "    'Toyota Sequoia SUV 2012', 'Toyota Camry Sedan 2012',\n",
        "    'Toyota Corolla Sedan 2012', 'Toyota 4Runner SUV 2012',\n",
        "    'Volkswagen Golf Hatchback 2012', 'Volkswagen Golf Hatchback 1991',\n",
        "    'Volkswagen Beetle Hatchback 2012', 'Volvo C30 Hatchback 2012',\n",
        "    'Volvo 240 Sedan 1993', 'Volvo XC90 SUV 2007',\n",
        "    'smart fortwo Convertible 2012',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTvwXrIbCFR5"
      },
      "source": [
        "We are now able to visualize some of the examples together with their bounding-boxes and class names. The following lines will do exactly this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZHzFCFk_OeR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "samples = train_ds.shuffle(1000).take(9)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "  ax = fig.add_subplot(f'33{i}')\n",
        "  image = sample['image']\n",
        "  label = CLASS_NAMES[sample['label']]\n",
        "\n",
        "  height, width, _ = image.shape\n",
        "  bbox = sample['bbox'] * tf.constant([height, width, height, width], tf.float32)\n",
        "  bbox_patch = patches.Rectangle((bbox[1], bbox[0]),\n",
        "                                 width=bbox[3] - bbox[1],\n",
        "                                 height=bbox[2] - bbox[0],\n",
        "                                 linewidth=5,\n",
        "                                 edgecolor='cyan',\n",
        "                                 facecolor='none')\n",
        "  ax.set_title(label)\n",
        "  ax.imshow(image)\n",
        "  ax.add_patch(bbox_patch) \n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6vY0-9BCaZ2"
      },
      "source": [
        "## Prepare data for model training\n",
        "\n",
        "Looks good! Since TFDS exposes all datasets as `tf.data.Datasets`, we can use this rich API to do all of the preprocessing, like batching, normalization, resizing etc. on the fly. I will not go into detail here, since this would go way beyond the scope of this demo notebook. However, if you are interested, consider reading through the official [tf.data Guide](https://www.tensorflow.org/guide/data). \n",
        "\n",
        "\n",
        "We will rescale our images to  be in the range of `[0, 1]`. We will also shuffle the data and divide it into minibatches of size 32. In the end, we return a prefetched version of the datasat, which means that we are going to overlap the preprocessing and model execution of a training step. While the model is executing training step `s`, the input pipeline is reading the data for step `s+1`. This is good practice to improve performance of the data input pipeline. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToGe-Li9Hh2O"
      },
      "source": [
        "Since we only deal with image classification in this notebook, we don't need to carry around the bounding-boxes of each observation. From the metadata above, we can see that the dataset has a pair of features declared as supervised keys. (`supervised_keys=('image', 'label'),`).\n",
        "\n",
        "We can therefore reload the dataset with the keyword argument `as_supervised` set to `True`. This will load a tuple of two Tensors instead of a dictionary of all features, which is exactly the format in which our model expects the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coA0U8IsHhjR"
      },
      "source": [
        "(train_ds, val_ds, test_ds) = tfds.load(\n",
        "    'cars196',\n",
        "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "    with_info=False,\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "normalize = tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "\n",
        "def prepare(ds, shuffle=False, batch_size=32, num_classes=196):\n",
        "  # Normalize images to [0, 1] and convert label to one-hot vector\n",
        "  ds = ds.map(lambda sample, label: (\n",
        "      normalize(tf.image.resize(sample, [224, 224])),\n",
        "      tf.one_hot(tf.cast(label, tf.uint8), num_classes)),\n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Batch all datasets\n",
        "  ds = ds.batch(batch_size)\n",
        "\n",
        "  return ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "train_ds = prepare(train_ds, shuffle=True)\n",
        "val_ds = prepare(val_ds)\n",
        "test_ds = prepare(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYHkAKb1h5AI"
      },
      "source": [
        "A careful reader may have wondered about the keras layer that we use for the rescaling, so let me go into a little more detail here to clarify on this. Indeed, the Keras preprocessing layer API is relatively new. Itâ€™s purpose is to build Keras-native input processing pipelines, which can be used as independent preprocessing code in non-Keras workflows, combined directly with Keras models, and exported as part of a Keras SavedModel. We use it independently by mapping it over our dataset. With this approach, data augmentation will happen asynchronously on the CPU, and is non-blocking. We could have also added the preprocessing layer to our model, which would data augmentation run on-device, synchronously with the rest of our layers, and benefit from GPU acceleration. Whatever way you prefer, itâ€™s just a matter of preference. For example, if you have heavy preprocessing routines that would benefit from GPU acceleration, you could attach the layers to your model and place them on a GPU. Additionally, since the preprocessing layers will be saved with your model, you can use them for standardization when you deploy your model without the need to reimplement this preprocessing logic on your deployment target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OP4Li3KCXZh"
      },
      "source": [
        "## Model definition\n",
        "\n",
        "We want to train a classification model quantization aware. We can use the TensorFlow Model Optimization toolkit for this. Since it is not a default package of the colab runtime, we first need to install it by issuing the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4SeIT5LQkiy"
      },
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiRNCzOTDxj_"
      },
      "source": [
        "The following function creates our model. We privide the shape in which we will pass the images to the model, as well as the number of classes in our dataset. The parameter `qat=True` controls wether we want to train the model quantisation aware or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVlUu5tQQehA"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "\n",
        "def get_model(in_shape, num_classes, qat=True):\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
        "                                                   input_shape=in_shape,\n",
        "                                                   weights='imagenet')\n",
        "    base_output = base_model.layers[-2]\n",
        "    outputs = tf.keras.layers.Dense(num_classes,\n",
        "                                    activation='softmax')(base_output.output)\n",
        "    model = tf.keras.models.Model(inputs=base_model.inputs,\n",
        "                                  outputs=outputs)\n",
        "\n",
        "    if qat:\n",
        "        model = tfmot.quantization.keras.quantize_model(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR0g97K7hBwp"
      },
      "source": [
        "The following cell loads our model architecture with the pretrained weights. If you want, you can change the `qat=True` argument to `qat=False` and compare the output. You will see, that quantization aware model has some extra parameters that are required in order to mitigate a large accuracy drop due to the smaller precision of the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUBf5K5JhGGs"
      },
      "source": [
        "model = get_model(in_shape=(224, 224, 3), num_classes=196, qat=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW_ENgIBEexL"
      },
      "source": [
        "The next few lines are optional. They can be used to monitor training progress via TensorBoard directly in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikWtBprN4WZV"
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsLpBxhYEu4x"
      },
      "source": [
        "Having everything prepared, we are ready to train our model quantization aware. We will use the high level Keras API to this end. Before calling, we will specify the number of steps of one epoch for training and validation. We can copy the number of samples in the training set from the `metadata` info above and divide it by our batch size of 32. Note that we have to hardcode the number of files, since we are not able to derive this number automatically with this particular dataset.\n",
        "\n",
        "\n",
        "We do also specify some callbacks that are used by Keras during the training process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCxGJJ5DWTH8"
      },
      "source": [
        "  train_steps = int(( 0.8 * 8144) / 32)\n",
        "  val_steps = int((0.2 * 8144) / 32)\n",
        "\n",
        "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "  \n",
        "  callbacks = [\n",
        "      tf.keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "      tensorboard_callback\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuJyUovmGsIM"
      },
      "source": [
        "Let's display the TensorBoard interface here. Once we start the training, you can navigate to this cell, select the tab scalards in the drop down menu in the top right corner and see a plot of the train/eval loss and accuracy, wich will get updated every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwgQCqDdGrO7"
      },
      "source": [
        "%tensorboard --logdir logdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7cXJJAGGDBW"
      },
      "source": [
        "Next, we compile our model with the Adam optimizer and a categorical crossentropy as a loss function. \n",
        "\n",
        "Finally, we can call `model.fit()` to train our model for 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXz-JN9WGDeT"
      },
      "source": [
        "  model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  model.fit(train_ds.repeat(), validation_data=val_ds, epochs=10, callbacks=callbacks,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=val_steps\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jOJprCCuQbo"
      },
      "source": [
        "model.evaluate(test_ds, steps=8041//32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Fhxumd02Dp"
      },
      "source": [
        "---\n",
        "\n",
        "![inovex logo mini240px.png](data:image/png;base64,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)\n",
        "\n",
        "Find more notebooks like this in our central repository (LINK).\n",
        "\n",
        "For in-depth article have a look at our [blog](https://www.inovex.de/blog).\n",
        "\n",
        "Shared with ðŸ’™ by [inovex.de](https://www.inovex.de)."
      ]
    }
  ]
}